import scipy.io.wavfile
import os
import numpy as np
import librosa
from scipy.spatial.distance import cdist
import numpy as np
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.layers import Dense, Dropout, PReLU, Input, BatchNormalization,Conv1D, Flatten, MaxPooling1D, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.regularizers import l1,l2,l1_l2
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from sklearn.decomposition import PCA as skPCA
from sklearn.metrics import confusion_matrix as cm
from sklearn.metrics import precision_recall_fscore_support as prf
import csv



corpuspath='x:/googlecorpus' # folder for speech dataset
unlabeled_set_size=12000 # number of samples for autoencoder training
lbl_trai_size=3000 # size of training set for supervised KWS evaluation
lbl_test_size=6000 # size of test set for supervised KWS evaluation
resultspath='f:/testcorpus' # folder to save the results as csv
lbl_trai_size=lbl_trai_size*2 # selecting twice as dataset will be split to half after shuffling for each iteration while supervised KWS training



# benchmark CNN for supervised KWS

def bmcnn():
 pt=5
 inputdim1=kws_trai_mfc.shape
 outputdim1=to_categorical(kws_trai_labelids).shape[1]
 input_flat1 = Input(shape=(inputdim1[1:]))
 h=Conv1D(64, kernel_size=32,strides=2, padding='same')(input_flat1)#
 h=BatchNormalization()(h)
 h=MaxPooling1D()(h)# 
 h=Flatten()(h) 
 output_layer1 = Dense(outputdim1, activation='softmax')(h)
 emodel1 = Model(input_flat1,output_layer1)
 emodel1.compile(optimizer='Adamax', loss='categorical_crossentropy')
 emodel1.summary()
 es = EarlyStopping(monitor='val_loss', mode='min',verbose=1,min_delta=0, patience=pt)
 hist= emodel1.fit(kws_trai_mfc,to_categorical(kws_trai_labelids),epochs=100,batch_size=32,shuffle=True,validation_split=0.5,callbacks=[es],verbose=1) 
 prediction=emodel1.predict(kws_test_mfc)
 print('acc',sum(np.argmax(prediction,axis=1)==kws_test_labelids)/len(prediction))
 print('wer',1-(sum(np.argmax(prediction,axis=1)==kws_test_labelids)/len(prediction)))
 wer=1-(sum(np.argmax(prediction,axis=1)==kws_test_labelids)/len(prediction))
 presi=prf(np.argmax(prediction,axis=1),kws_test_labelids)[0]
 recal=prf(np.argmax(prediction,axis=1),kws_test_labelids)[1]
 avpresi=prf(np.argmax(prediction,axis=1),kws_test_labelids,average='weighted')[0]
 avrecal=prf(np.argmax(prediction,axis=1),kws_test_labelids,average='weighted')[1]
 return wer, presi, recal, avpresi, avrecal


# feedforward DNN for supervised KWS

def discrim(indata,outdata1,werval,werlabelval1,epc,dvspt,dpt):
 outdata=to_categorical(outdata1)
 werlabelval=to_categorical(werlabelval1)
 oact='softmax' 
 hact='relu'
 spl=len(indata)
 inputdim=len(indata[0])
 outputdim=len(outdata[0])
 input_flat1 = Input(shape=(inputdim,))
 hidden_layer1 = Dense(int((outputdim+inputdim)/2))(input_flat1)
 h2=BatchNormalization()(hidden_layer1)
 h3=PReLU(alpha_initializer='zeros')(h2)
 h4=Dropout(0.1)(h3)
 output_layer1 = Dense(outputdim, activation=oact)(h4)
 emodel1 = Model(input_flat1,output_layer1)
 emodel1.compile(optimizer='Nadam', loss='categorical_crossentropy')
 emodel1.summary()
 #plot_model(emodel1, to_file='dmodel.png')
 es = EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=dpt)
 hist= emodel1.fit(indata,outdata,epochs=epc,batch_size=32,shuffle=True,validation_split=dvspt,callbacks=[es])
 flat_outa = emodel1.predict(werval)
 flatword = np.argmax((flat_outa),axis=1)
 outword = np.argmax((werlabelval),axis=1)
 flaterror=0
 for j in range(0, len(werval)):
  if flatword[j] == outword[j]:
   flaterror = flaterror
  else:
   flaterror=flaterror+1
 
 percenterror=(flaterror*100)/len(werval)
 presi=prf(flatword,werlabelval1)[0]
 recal=prf(flatword,werlabelval1)[1]
 avpresi=prf(flatword,werlabelval1,average='weighted')[0]
 avrecal=prf(flatword,werlabelval1,average='weighted')[1]
 return percenterror, hist, presi, recal, avpresi, avrecal

# proposed AE with position constraint

def ae_pos_abx(indata,outdata,epc,opt,lss,avspt,discval,disclabelval,werval,werlabelval,apt,l1r,l2r):
 #cp = ModelCheckpoint(fp)
 #cbl = [cp]
 inputdim=len(indata[0])
 inputlayer = Input(shape=(inputdim,))
 outputdim1=len(outdata[0][0])
 outputdim2=len(outdata[1][0])
 L=Dense(300,kernel_regularizer=l2(0.0))(inputlayer)
 #L=Reshape((300,))(L)
 L= BatchNormalization()(L)
 L=PReLU(activity_regularizer=l1(0.0))(L)
 L=Dropout(0.1)(L)
 L=Dense(150,kernel_regularizer=l2(0.0))(L)
 L= BatchNormalization()(L)
 #L=PReLU(activity_regularizer=l1(0.0))(L)
 #L=Dropout(0.1)(L)
 emb_layer=Dense(75)(L)
 #L=PReLU(activity_regularizer=l1(0.0))(L)
 #emb_layer=BatchNormalization(name='embedding')(L)
 houtlayer1 = Dense(300)(emb_layer)
 houtlayer1a=BatchNormalization()(houtlayer1)
 #houtlayer1b=PReLU()(houtlayer1a)
 houtlayer1bd=Dropout(0.1)(houtlayer1a)
 houtlayer2 = Dense(50,kernel_regularizer=l2(0.000))(emb_layer)
 houtlayer2a= BatchNormalization()(houtlayer2)
 houtlayer2b=PReLU(activity_regularizer=l1(0.0))(houtlayer2a)
 #houtlayer2c=Dropout(0.1)(houtlayer2b)
 #houtlayer2d = Dense(25,kernel_regularizer=l2(0.000))(houtlayer2b)
 #output
 outputlayer1 = Dense(outputdim1, name='primary-output__MFCC-reconstruction')(houtlayer1bd)
 outputlayer2 = Dense(outputdim2, name='secondary-task__geometric-position',kernel_regularizer=l1_l2(l1=l1r, l2=l2r))(houtlayer2b)#,kernel_constraint=MinMaxNorm(min_value=0.5,max_value=1.5, axis=0)
 embedmodel = Model(inputlayer,emb_layer)
 regenmodel = Model(inputlayer,[outputlayer1,outputlayer2])#,outputlayer3,outputlayer4,outputlayer5
 regenmodel.compile(optimizer=opt, loss=lss)
 regenmodel.summary()
 #plot_model(regenmodel, to_file='model.png')
 es = EarlyStopping(monitor='loss', mode='min',verbose=1, patience=apt)
 #es = EarlyStopping(monitor='loss', mode='min',verbose=1,min_delta=0, patience=1)
 aehist=regenmodel.fit(indata,outdata,epochs=epc,batch_size=32,shuffle=True,validation_split=avspt,callbacks=[es])
 #aehist=regenmodel.fit(indata,outdata,epochs=epc,batch_size=32,shuffle=True,callbacks=[es])
 embeddingtrain=embedmodel.predict(indata)
 plt.plot(embeddingtrain[0])
 embeddingval=embedmodel.predict(discval)
 werembval=embedmodel.predict(werval)
 wer,hist, presi, recal, avpresi, avrecal=discrim(embeddingval,disclabelval,werembval,werlabelval,500,0.5,5)
 print('wer ',wer)
 return wer, embeddingval, embeddingtrain,aehist, presi, recal, avpresi, avrecal



## load audio files with filenames and sample rates

wavelist=[]
sratlist=[]
filelist=[]
for keywordpath in os.listdir(corpuspath):
    try:
        for audiofile in os.listdir(corpuspath+'/'+keywordpath):
            srate,audio=scipy.io.wavfile.read(corpuspath+'/'+keywordpath+'/'+audiofile)
            wavelist.append(audio)
            sratlist.append(srate)
            filelist.append(keywordpath+'/'+audiofile)
    except:
        pass

# extract spectral features from speech

rawa=np.zeros((len(wavelist),16000))
for i in range(len(wavelist)):
  rawa[i][0:len(wavelist[i])]=wavelist[i]
mfca=[[] for _ in range(len(rawa))]
lpsa=[[] for _ in range(len(rawa))]

for i in range(len(rawa)):
 mfca[i]=librosa.feature.mfcc(y=rawa[i], sr=sratlist[i])
 lpsa[i]=librosa.feature.melspectrogram(y=rawa[i], sr=sratlist[i], n_fft=1025)
mfca=np.array(mfca)
lpsa=np.array(lpsa)

f=open(corpuspath+'/testing_list.txt','r')
testlist=[line.rstrip() for line in f]
f.close()
f=open(corpuspath+'/validation_list.txt','r')
valilist=[line.rstrip() for line in f]
f.close()

# segregate unlabaled set for unsupervised AE training

unlabaledmfc=mfca[np.in1d(filelist,testlist+valilist, invert=True)]
unlabaledlps=lpsa[np.in1d(filelist,testlist+valilist, invert=True)]

# segregate training and test sets for supervised KWS evaluation

labeltrailps=lpsa[np.in1d(filelist,valilist)]
labeltraimfc=mfca[np.in1d(filelist,valilist)]
labeltestlps=lpsa[np.in1d(filelist,testlist)]
labeltestmfc=mfca[np.in1d(filelist,testlist)]
labeltraifle=np.array(filelist)[np.in1d(filelist,valilist)]
labeltestfle=np.array(filelist)[np.in1d(filelist,testlist)]

labeltrai=[[] for _ in range(len(labeltraifle))]
labeltest=[[] for _ in range(len(labeltestfle))]

for i in range(len(labeltraifle)):
 labeltrai[i]=labeltraifle[i].split('/')[0]

for i in range(len(labeltestfle)):
 labeltest[i]=labeltestfle[i].split('/')[0]

labeltest=np.array(labeltest)
labeltrai=np.array(labeltrai)
labelunique=np.unique(labeltrai)

trailabelids=np.zeros(len(labeltrai))
testlabelids=np.zeros(len(labeltest))
for i in range(len(labeltrai)):
  trailabelids[i]=np.where(labeltrai[i]==labelunique)[0][0]

for i in range(len(labeltest)):
  testlabelids[i]=np.where(labeltest[i]==labelunique)[0][0]

trailabelids=trailabelids.astype('int')
testlabelids=testlabelids.astype('int')



# retain number of selected samples

np.random.seed(1)
ridcs=np.arange(len(unlabaledmfc))
np.random.shuffle(ridcs)
ridcs=ridcs[:unlabeled_set_size]
ridcs1=np.arange(len(labeltraimfc))
np.random.shuffle(ridcs1)
ridcs1=ridcs1[0:lbl_trai_size]
ridcs2=np.arange(len(labeltestmfc))
np.random.shuffle(ridcs2)
ridcs2=ridcs2[0:lbl_test_size]


ae_inp_mfc=unlabaledmfc[ridcs]
ae_pos_lps=unlabaledlps[ridcs]

kws_trai_mfc=labeltraimfc[ridcs1]
kws_trai_label=labeltrai[ridcs1]
kws_trai_labelids=trailabelids[ridcs1]

kws_test_mfc=labeltestmfc[ridcs2]
kws_test_label=labeltest[ridcs2]
kws_test_labelids=testlabelids[ridcs2]




# flatten the feature vectors for transforamtion by AE model

kws_test_mfcflat=kws_test_mfc.reshape(len(kws_test_mfc),(len(kws_test_mfc[0])*len(kws_test_mfc[0][0])))
kws_trai_mfcflat=kws_trai_mfc.reshape(len(kws_trai_mfc),(len(kws_trai_mfc[0])*len(kws_trai_mfc[0][0])))
ae_inp_mfcflat=ae_inp_mfc.reshape(len(ae_inp_mfc),(len(ae_inp_mfc[0])*len(ae_inp_mfc[0][0])))
ae_pos_lpsflat=ae_pos_lps.reshape(len(ae_pos_lps),len(ae_pos_lps[0])*len(ae_pos_lps[0][0]))



# computation of mean anchor vector and postion scalars

pfeat=ae_pos_lpsflat # ae_pos_lpsflat, ae_inp_mfcflat
#pfeat=ae_inp_mfcflat[:,5*32:(10)*32] # ae_pos_lpsflat, ae_inp_mfcflat[:,5*32:(10)*32]
acr=np.mean(pfeat,axis=0)
acr=np.reshape(acr,(1,-1))
d=cdist(pfeat,acr, metric='cosine')#correlation, cosine



# training and evaluation for proposed as well as benchmark model

for i in range(10):
 wercm, cmpresi, cmrecal, cmavpresi, cmavrecal=bmcnn()
 wer_v_p, embeding_v_p, embeding_t_p,hist_p, appresi, aprecal, apavpresi, apavrecal =ae_pos_abx(ae_inp_mfcflat,[ae_inp_mfcflat,d],500,'Adamax',['mse','mse'],0.0,kws_trai_mfcflat,kws_trai_labelids,kws_test_mfcflat,kws_test_labelids,5,0.00,0.0)
 with open(resultspath+'/results.csv', 'a', newline='') as csvfile:
     res = csv.writer(csvfile)
     res.writerow(['wercm','cmpresi','cmrecal','cmavpresi','cmavrecal','wer_v_p','appresi','aprecal','apavpresi','apavrecal'])
     res.writerow([wercm,cmpresi,cmrecal,cmavpresi,cmavrecal,wer_v_p,appresi,aprecal,apavpresi,apavrecal])

## pca plots for visualization


trainlabeluniqueids=np.unique(kws_trai_labelids)
ltl=len(trainlabeluniqueids)-0
trainlabelidx=[[]]*ltl
for i in range(ltl):
 trainlabelidx[i]=np.where(trainlabeluniqueids[i]==kws_trai_labelids)
 

#mrkr=[".",",","o","v","^","<",">","s","p","P","H","x","X","D","d",".",",","o","v","^","<",">","s","p","P","H","x","X","D","d"]


posm=[[]]*ltl
mfcm=[[]]*ltl
for i in range(ltl):
    posm[i]=np.mean(embeding_t_p[trainlabelidx[i][0][:100]],axis=0)
    mfcm[i]=np.mean(ae_inp_mfcflat[trainlabelidx[i][0][:100]],axis=0)
    
    
posm=np.array(posm)
mfcm=np.array(mfcm)


X=mfcm
X = (X - X.min())/(X.max() - X.min())
pca = skPCA(n_components=2)
transformed = pca.fit_transform(X)
plt.figure()
for i in range(0,len(X)):
 plt.scatter(transformed[i][0],transformed[i][1])#,label=np.unique(trainlabel)[i], marker=mrkr[i],s=50)#, color=colors[i],marker=mrkr[i],s=50)#mrkr[i]
 plt.annotate(np.unique(kws_trai_label)[i], (transformed[i][0],transformed[i][1]))
plt.xlim(-1, 1)
plt.ylim(-1, 1)
plt.title('PCA-projection_MFCC_mean-of-points')
#plt.legend()
plt.savefig('MFCC_30',dpi=300)
plt.show()
plt.close()


X= posm
X = (X - X.min())/(X.max() - X.min())
pca = skPCA(n_components=2)
transformed = pca.fit_transform(X)
plt.figure()
for i in range(0,len(X)):
 plt.scatter(transformed[i][0],transformed[i][1],s=50)#,label=np.unique(trainlabel)[i], marker=mrkr[i],s=50)#, color=colors[i], marker=mrkr[i],s=50)#
 plt.annotate(np.unique(kws_trai_label)[i], (transformed[i][0],transformed[i][1]))
plt.xlim(-1, 1)
plt.ylim(-1, 1)
plt.title('PCA-projection_Transform_with-Position-constraint_mean-of-points')
plt.savefig('AE_PROJECTION_30',dpi=300)
plt.show()
plt.close()



# precision and recall value display based on, vectors for all iterations, extracted from results.csv
'''
cmpresi=np.array([0.55033557,0.49295775,0.12676056,0.38607595,0.23853211,0.34763948,0.5,0.61751152,0.30414747,0.60122699,0.69918699,0.30543933,0.32191781,0.24215247,0.43303571,0.50212766,0.46118721,0.35616438,0.55217391,0.65533981,0.81547619,0.58490566,0.46919431,0.37339056,0.51807229,0.32758621,0.30555556,0.4527027,0.79910714,0.67317073])+np.array([0.3557047,0.55633803,0.21126761,0.1835443,0.23853211,0.56652361,0.33333333,0.59907834,0.40092166,0.69325153,0.6097561,0.23849372,0.24657534,0.16143498,0.33035714,0.58297872,0.44292237,0.33333333,0.51304348,0.73786408,0.63690476,0.77830189,0.61137441,0.43347639,0.39759036,0.49568966,0.57142857,0.41216216,0.53571429,0.53170732])+np.array([0.40939597,0.71830986,0.26056338,0.1835443,0.53669725,0.41201717,0.42682927,0.48847926,0.4562212,0.58895706,0.79674797,0.32635983,0.24657534,0.47982063,0.21875,0.47659574,0.36073059,0.63013699,0.45652174,0.5,0.71428571,0.75943396,0.40758294,0.29613734,0.6686747,0.56896552,0.1984127,0.46621622,0.55803571,0.45853659])+np.array([0.31543624,0.52816901,0.33802817,0.29113924,0.21100917,0.2832618,0.45934959,0.52073733,0.29953917,0.65030675,0.62601626,0.61924686,0.65068493,0.43497758,0.25,0.68510638,0.34703196,0.3196347,0.43043478,0.68932039,0.76190476,0.48584906,0.54028436,0.34763948,0.3313253,0.43103448,0.14285714,0.58108108,0.44196429,0.68292683])+np.array([0.29530201,0.4084507,0.35211268,0.2278481,0.33027523,0.56652361,0.34552846,0.61751152,0.49308756,0.49079755,0.68292683,0.35983264,0.52739726,0.39910314,0.08928571,0.56595745,0.40182648,0.38812785,0.58695652,0.65533981,0.71428571,0.63679245,0.45023697,0.48927039,0.37951807,0.54741379,0.36111111,0.26351351,0.54464286,0.36585366])+np.array([0.45637584,0.51408451,0.38028169,0.2278481,0.21100917,0.36051502,0.28861789,0.56221198,0.5437788,0.55828221,0.73170732,0.51046025,0.43150685,0.2735426,0.3125,0.51489362,0.53881279,0.34246575,0.63043478,0.43203883,0.71428571,0.41981132,0.507109,0.56223176,0.20481928,0.29741379,0.26984127,0.45945946,0.70089286,0.71707317])+np.array([0.67114094,0.5915493,0.51408451,0.15189873,0.33944954,0.63948498,0.24796748,0.42857143,0.35023041,0.6993865,0.57723577,0.26778243,0.45205479,0.32286996,0.45982143,0.74893617,0.43378995,0.29680365,0.40869565,0.62621359,0.80952381,0.5990566,0.56872038,0.2832618,0.27108434,0.49568966,0.22222222,0.25675676,0.59821429,0.56097561])+np.array([0.51006711,0.53521127,0.3028169,0.34177215,0.41284404,0.55364807,0.44715447,0.53917051,0.21198157,0.52760736,0.7398374,0.42259414,0.38356164,0.21973094,0.44642857,0.47659574,0.24657534,0.29223744,0.52173913,0.49514563,0.61904762,0.70754717,0.54028436,0.42060086,0.12650602,0.5,0.57142857,0.47972973,0.59821429,0.76585366])+np.array([0.44966443,0.45774648,0.45070423,0.33544304,0.13761468,0.57081545,0.5203252,0.62211982,0.56221198,0.49079755,0.77235772,0.41422594,0.5,0.24663677,0.17410714,0.55744681,0.50228311,0.19178082,0.42173913,0.76213592,0.74404762,0.66509434,0.4549763,0.45493562,0.27710843,0.5,0.35714286,0.47297297,0.50892857,0.3804878,])+np.array([0.44966443,0.43661972,0.36619718,0.43037975,0.36238532,0.60944206,0.34146341,0.52534562,0.61290323,0.65030675,0.7804878,0.40585774,0.29452055,0.39461883,0.11160714,0.42553191,0.30136986,0.38812785,0.54347826,0.67961165,0.83333333,0.51415094,0.41706161,0.40343348,0.36746988,0.38793103,0.26587302,0.52702703,0.54910714,0.61463415])
cmrecal=np.array([0.41,0.76086957,0.72,0.24302789,0.58426966,0.58273381,0.3129771,0.47349823,0.44295302,0.46889952,0.48314607,0.46202532,0.61842105,0.52941176,0.37164751,0.62105263,0.34827586,0.30952381,0.46181818,0.51724138,0.61160714,0.58767773,0.80487805,0.48066298,0.35390947,0.58461538,0.48427673,0.4527027,0.41339492,0.50181818])+np.array([0.53535354,0.632,0.53571429,0.3625,0.53061224,0.46478873,0.44086022,0.50583658,0.31294964,0.4484127,0.90361446,0.64044944,0.65454545,0.53731343,0.38743455,0.57322176,0.41452991,0.365,0.48760331,0.33853007,0.8359375,0.39855072,0.50194553,0.37686567,0.44,0.53240741,0.26086957,0.50833333,0.66298343,0.72666667])+np.array([0.53508772,0.4063745,0.69811321,0.31521739,0.31283422,0.62745098,0.40229885,0.56989247,0.30555556,0.58181818,0.37547893,0.66101695,0.46153846,0.39776952,0.40163934,0.7,0.4702381,0.28336756,0.56451613,0.70068027,0.86956522,0.5,0.72881356,0.41818182,0.29442971,0.41772152,0.42016807,0.41317365,0.66489362,0.7768595,])+np.array([0.38211382,0.67567568,0.42105263,0.27058824,0.52272727,0.61111111,0.31301939,0.62777778,0.36723164,0.4953271,0.72641509,0.2327044,0.25815217,0.29216867,0.38888889,0.48203593,0.45508982,0.40935673,0.47142857,0.54198473,0.79503106,0.86554622,0.70807453,0.44505495,0.46610169,0.54054054,0.42857143,0.40758294,0.58928571,0.59574468])+np.array([0.41121495,0.79452055,0.39370079,0.36734694,0.48,0.49438202,0.34412955,0.40361446,0.29234973,0.61068702,0.72413793,0.47777778,0.27598566,0.35458167,0.47619048,0.54508197,0.36363636,0.36170213,0.32451923,0.5625,0.67039106,0.63679245,0.71969697,0.40282686,0.39130435,0.49803922,0.32155477,0.61904762,0.63874346,0.76530612])+np.array([0.47222222,0.68224299,0.40909091,0.31858407,0.5974026,0.47191011,0.47651007,0.55963303,0.24532225,0.43127962,0.49450549,0.34078212,0.57272727,0.49193548,0.37837838,0.6142132,0.33810888,0.33039648,0.41786744,0.7295082,0.8,0.76724138,0.62573099,0.33418367,0.53968254,0.61061947,0.34,0.45333333,0.50809061,0.45230769])+np.array([0.28328612,0.672,0.28968254,0.42105263,0.45121951,0.40599455,0.50833333,0.67883212,0.32067511,0.44186047,0.73958333,0.64,0.42857143,0.39130435,0.2689295,0.33333333,0.33333333,0.40880503,0.58024691,0.58371041,0.64454976,0.66842105,0.50632911,0.48529412,0.625,0.48523207,0.42748092,0.61290323,0.60089686,0.72327044])+np.array([0.42222222,0.63333333,0.51807229,0.25116279,0.37815126,0.39692308,0.38327526,0.53181818,0.41818182,0.58503401,0.45959596,0.61212121,0.48275862,0.46666667,0.3257329,0.65882353,0.71052632,0.44137931,0.45977011,0.71830986,0.85245902,0.6147541,0.69090909,0.38888889,0.53846154,0.53456221,0.24242424,0.42771084,0.59030837,0.43131868])+np.array([0.40606061,0.79268293,0.31527094,0.29608939,0.55555556,0.39465875,0.30917874,0.61643836,0.26124197,0.58394161,0.53672316,0.49253731,0.30165289,0.37931034,0.41052632,0.60930233,0.34482759,0.6,0.60248447,0.45772595,0.79617834,0.564,0.768,0.37992832,0.58974359,0.47933884,0.36734694,0.51470588,0.7037037,0.77227723])+np.array([0.40853659,0.84931507,0.40310078,0.26356589,0.44886364,0.43692308,0.39252336,0.42066421,0.23623446,0.44915254,0.49740933,0.49489796,0.5443038,0.3876652,0.38461538,0.7518797,0.5840708,0.40669856,0.5186722,0.53639847,0.50359712,0.77304965,0.79279279,0.36153846,0.47286822,0.58064516,0.36413043,0.37142857,0.67213115,0.56502242])
appresi=np.array([0.44966443,0.54225352,0.3943662,0.26582278,0.41743119,0.63948498,0.47560976,0.51612903,0.37327189,0.58895706,0.79674797,0.46443515,0.41780822,0.52466368,0.40178571,0.53617021,0.543379,0.53424658,0.49130435,0.68932039,0.81547619,0.69811321,0.5450237,0.5751073,0.48192771,0.45689655,0.44444444,0.58108108,0.79464286,0.67317073])+np.array([0.48993289,0.58450704,0.27464789,0.34810127,0.43119266,0.67381974,0.44715447,0.57603687,0.39170507,0.69325153,0.74796748,0.48117155,0.39726027,0.58744395,0.43303571,0.63404255,0.51598174,0.49771689,0.55217391,0.67475728,0.77380952,0.65566038,0.58293839,0.45064378,0.51204819,0.5387931,0.48015873,0.56081081,0.6875,0.68292683])+np.array([0.59731544,0.54225352,0.3943662,0.27848101,0.51834862,0.68240343,0.42276423,0.57603687,0.42396313,0.64417178,0.77235772,0.45188285,0.47945205,0.47085202,0.42857143,0.6,0.55707763,0.47488584,0.56086957,0.66019417,0.73809524,0.74528302,0.63981043,0.53648069,0.53012048,0.55172414,0.50396825,0.48648649,0.70089286,0.70731707])+np.array([0.4966443,0.59859155,0.35915493,0.32911392,0.52293578,0.63519313,0.48780488,0.58986175,0.46543779,0.63803681,0.75609756,0.45188285,0.46575342,0.5426009,0.41517857,0.52340426,0.543379,0.42009132,0.55652174,0.68446602,0.79761905,0.67924528,0.55924171,0.472103,0.36144578,0.49568966,0.45634921,0.58783784,0.71875,0.73170732])+np.array([0.57718121,0.63380282,0.41549296,0.29746835,0.3440367,0.70386266,0.53252033,0.57603687,0.48387097,0.64417178,0.73170732,0.53556485,0.50684932,0.48430493,0.34375,0.59574468,0.55707763,0.51141553,0.56521739,0.73300971,0.7797619,0.66509434,0.62559242,0.50214592,0.61445783,0.49137931,0.49603175,0.57432432,0.70089286,0.70731707])+np.array([0.5033557,0.57746479,0.3943662,0.30379747,0.38990826,0.67381974,0.41463415,0.53917051,0.42857143,0.6196319,0.73170732,0.51046025,0.47945205,0.48430493,0.40625,0.61276596,0.55707763,0.456621,0.46956522,0.69902913,0.70238095,0.72169811,0.58767773,0.45064378,0.53012048,0.52155172,0.55555556,0.55405405,0.72321429,0.68292683])+np.array([0.51006711,0.62676056,0.44366197,0.30379747,0.35321101,0.72103004,0.48780488,0.5437788,0.42396313,0.65644172,0.67479675,0.51464435,0.4109589,0.53363229,0.41517857,0.61702128,0.58447489,0.49315068,0.54347826,0.7184466,0.79761905,0.67924528,0.58293839,0.48497854,0.43975904,0.60344828,0.53968254,0.58108108,0.75446429,0.70243902])+np.array([0.51677852,0.61267606,0.4084507,0.35443038,0.4266055,0.67381974,0.39837398,0.55760369,0.50230415,0.6993865,0.75609756,0.46025105,0.39726027,0.53363229,0.32589286,0.5787234,0.52054795,0.52511416,0.55652174,0.68932039,0.82738095,0.66509434,0.59241706,0.40772532,0.44578313,0.53017241,0.51984127,0.60810811,0.78125,0.73170732])+np.array([0.46979866,0.55633803,0.35915493,0.37341772,0.38073394,0.72103004,0.47560976,0.53917051,0.42396313,0.63190184,0.71544715,0.49790795,0.51369863,0.53811659,0.39285714,0.62553191,0.52968037,0.50228311,0.54347826,0.69417476,0.75595238,0.73584906,0.66824645,0.49356223,0.43975904,0.60344828,0.54761905,0.56756757,0.75,0.71707317])+np.array([0.47651007,0.57746479,0.37323944,0.25949367,0.49082569,0.65236052,0.44308943,0.59907834,0.46543779,0.67484663,0.70731707,0.42259414,0.43150685,0.48430493,0.27232143,0.54893617,0.52511416,0.51598174,0.55652174,0.71359223,0.78571429,0.77358491,0.64454976,0.48497854,0.5,0.50862069,0.57936508,0.52027027,0.71428571,0.73658537])
aprecal=np.array([0.40361446,0.57462687,0.53333333,0.33333333,0.46192893,0.58431373,0.47560976,0.55445545,0.37327189,0.52747253,0.57988166,0.56345178,0.44525547,0.50431034,0.44776119,0.68478261,0.49377593,0.43984962,0.50672646,0.66981132,0.73655914,0.77083333,0.69277108,0.4527027,0.46511628,0.54358974,0.4497992,0.45989305,0.71774194,0.6359447,])+np.array([0.44242424,0.66935484,0.42857143,0.38194444,0.48205128,0.53220339,0.42307692,0.6377551,0.39170507,0.55940594,0.6618705,0.50218341,0.46031746,0.48880597,0.49489796,0.65350877,0.49130435,0.45416667,0.58256881,0.70558376,0.74712644,0.87421384,0.71511628,0.46666667,0.47752809,0.51229508,0.40468227,0.51875,0.7,0.66985646])+np.array([0.40825688,0.62601626,0.5045045,0.275,0.452,0.55017301,0.492891,0.64102564,0.36947791,0.50724638,0.60509554,0.5046729,0.46052632,0.53030303,0.5748503,0.61304348,0.50205761,0.60818713,0.56578947,0.69035533,0.775,0.76328502,0.75842697,0.48638132,0.51461988,0.63054187,0.44097222,0.52941176,0.69777778,0.70731707])+np.array([0.45679012,0.58219178,0.55434783,0.44444444,0.52534562,0.58964143,0.47619048,0.55411255,0.36996337,0.50241546,0.52247191,0.51674641,0.53125,0.484,0.52840909,0.57746479,0.61979167,0.53179191,0.52892562,0.61842105,0.68717949,0.77837838,0.75159236,0.4296875,0.32967033,0.53488372,0.42910448,0.56493506,0.72197309,0.65789474])+np.array([0.49142857,0.58441558,0.51754386,0.34814815,0.47770701,0.58362989,0.4906367,0.65445026,0.39622642,0.5801105,0.60810811,0.54468085,0.5,0.51923077,0.47530864,0.61403509,0.53275109,0.53080569,0.57522124,0.64529915,0.79393939,0.76630435,0.76744186,0.48148148,0.54545455,0.54285714,0.43103448,0.52147239,0.72018349,0.66210046])+np.array([0.54347826,0.54304636,0.448,0.43243243,0.42713568,0.54703833,0.44155844,0.65363128,0.37349398,0.68243243,0.60402685,0.54954955,0.51094891,0.38848921,0.45959596,0.59259259,0.4765625,0.46296296,0.53731343,0.67605634,0.72392638,0.70506912,0.74698795,0.44303797,0.47826087,0.54504505,0.47457627,0.56551724,0.72972973,0.64220183])+np.array([0.41758242,0.55625,0.48091603,0.384,0.47826087,0.55813953,0.52863436,0.55924171,0.34456929,0.56914894,0.61029412,0.55909091,0.45454545,0.48571429,0.45365854,0.60416667,0.58447489,0.50232558,0.56306306,0.67579909,0.68717949,0.8,0.72781065,0.51834862,0.51408451,0.5982906,0.48920863,0.5443038,0.71914894,0.77837838])+np.array([0.45833333,0.57236842,0.54716981,0.46280992,0.51955307,0.5147541,0.47115385,0.66120219,0.35620915,0.5158371,0.58860759,0.56410256,0.42335766,0.44402985,0.50694444,0.58369099,0.6031746,0.49356223,0.58715596,0.71717172,0.7020202,0.77472527,0.73099415,0.45023697,0.49333333,0.58293839,0.41987179,0.50847458,0.71428571,0.67873303])+np.array([0.37037037,0.53378378,0.57303371,0.34302326,0.54966887,0.54723127,0.41489362,0.61904762,0.35521236,0.62048193,0.704,0.56937799,0.4601227,0.53097345,0.47826087,0.67741935,0.58883249,0.51162791,0.61576355,0.6875,0.70555556,0.82105263,0.68115942,0.43726236,0.52142857,0.51851852,0.51879699,0.51533742,0.78139535,0.71014493])+np.array([0.38378378,0.56551724,0.43089431,0.48809524,0.44957983,0.56716418,0.42084942,0.68062827,0.36861314,0.53921569,0.60839161,0.52331606,0.44055944,0.5320197,0.42361111,0.64824121,0.55825243,0.4501992,0.63681592,0.70673077,0.76744186,0.70689655,0.71578947,0.48290598,0.46111111,0.62105263,0.41011236,0.53846154,0.77669903,0.64255319])

# sample numbers in the dataset from the corpus paper

key=['bed','bird','cat','dog','down','eight','five','four','go','happy','house','left','marvin','nine','no','off','on','one','right','seven','sheila','six','stop','three','tree','two','up','wow','yes','zero']
samp=np.array([2014,2064,2031,2128,3917,3787,4052,3728,3880,2054,2113,3801,2100,3934,3941,3745,3845,3890,3778,3998,2022,3860,3872,3727,1759,3880,3723,2123,4044,4052])

# precision recall plots

X=samp
X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))
X_scaled = X_std * (0.2 +0.2) -0.2

plt.figure()
plt.plot(cmpresi/10,label='MFCC_CNN',marker='.')
plt.plot(appresi/10,label='AE-REP_DNN',marker='.')
plt.title('Precision')
plt.xlabel('Keyword ID')
plt.legend()
plt.savefig('f:/spatial/precision',dpi=300)
plt.show()
plt.figure()
plt.plot(cmrecal/10,label='MFCC_CNN',marker='.')
plt.plot(aprecal/10,label='AE-REP_DNN',marker='.')
plt.title('Recall')
plt.xlabel('Keyword ID')
plt.legend()
plt.savefig('f:/spatial/recall',dpi=300)
plt.show()
plt.figure()
plt.plot(X_scaled,label='Samples_scaled',marker='.',linewidth=0.5)
plt.plot((appresi/10)-(cmpresi/10),label='Score_difference',marker='.')
plt.title('Precision_Difference')
plt.xlabel('Keyword ID')
plt.legend()
plt.savefig('f:/spatial/precision_difference',dpi=300)
plt.show()
plt.figure()
plt.plot(X_scaled,label='Samples_scaled',marker='.',linewidth=0.5)
plt.plot((aprecal/10)-(cmrecal/10),label='Score_difference',marker='.')
plt.title('Recall_difference')
plt.xlabel('Keyword ID')
plt.legend()
plt.savefig('f:/spatial/recall_difference',dpi=300)
plt.show()

'''
